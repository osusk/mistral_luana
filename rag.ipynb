{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a54b7d",
   "metadata": {},
   "source": [
    "# RAG for ColaborEJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab92dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gui\\Documents\\USP\\TCC\\mistral_luana\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3667: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047abc99b69f4c7aae2e7b70285ba70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): MistralRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "nb_4bit_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"rhaymison/Mistral-portuguese-luana-7b\",\n",
    "    quantization_config=nb_4bit_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rhaymison/Mistral-portuguese-luana-7b\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf04e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\Gui\\AppData\\Local\\Temp\\ipykernel_11452\\1090671760.py:8: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", \n",
    "                model=model, \n",
    "                device_map='auto', \n",
    "                tokenizer=tokenizer,\n",
    "                use_cache = True, \n",
    "                max_new_tokens=1000)\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052c60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(pdf_file):\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    pages = loader.load()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902eb39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer\n",
    "the question. If you don't know the answer, say that you\n",
    "don't know. DON'T MAKE UP ANYTHING.\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7578bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_splitter():\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,\n",
    "                                               chunk_overlap = 500,\n",
    "                                               length_function=len,\n",
    "                                               separators=[\"\\n\\n\", \"\\n\", \" \"])\n",
    "    return text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ebbc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gui\\AppData\\Local\\Temp\\ipykernel_11452\\640221044.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings_function():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name =\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    return embeddings\n",
    "embedding_function = get_embeddings_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f35d0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def create_vectorstore(chunks, embedding_function, vectorstore_path):\n",
    "\n",
    "    # Create a list of unique ids for each document based on the content\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "    \n",
    "    # Ensure that only unique docs with unique ids are kept\n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    \n",
    "    unique_chunks = [] \n",
    "    for chunk, id in zip(chunks, ids):     \n",
    "        if id not in unique_ids:       \n",
    "            unique_ids.add(id)\n",
    "            unique_chunks.append(chunk) \n",
    "\n",
    "    # Create a new Chroma database from the documents\n",
    "    vectorstore = Chroma.from_documents(documents=unique_chunks, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function, \n",
    "                                        persist_directory = vectorstore_path)\n",
    "\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7255664a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.32553651341390677}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "evaluator = load_evaluator(evaluator = \"embedding_distance\",\n",
    "                           embeddings = embedding_function)\n",
    "evaluator.evaluate_strings(prediction= \"cat\", reference=\"Animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d79366fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_pdf_file(pdf_file):\n",
    "    text_splitter = get_text_splitter()\n",
    "    chunks = text_splitter.split_documents(load_pdf(pdf_file))\n",
    "    # Create vectorstore\n",
    "    vectorstore = create_vectorstore(chunks=chunks, \n",
    "                                    embedding_function=embedding_function, \n",
    "                                    vectorstore_path=\"vectorstore_diretivas\")\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9bd0260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever and get relevant chunks\n",
    "def get_retriver(question, vectorstore):\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "    relevant_chunks = retriever.invoke(question)\n",
    "    return relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59cd9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(question, vectorstore):\n",
    "    relevant_chunks = get_retriver(question = question, vectorstore = vectorstore)\n",
    "    # Concatenate context text\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in relevant_chunks])\n",
    "\n",
    "    # Create prompt\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, \n",
    "                                    question = question)\n",
    "    response = llm.invoke(prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55ad6965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gui\\Documents\\USP\\TCC\\mistral_luana\\venv\\Lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n",
      "C:\\Users\\Gui\\AppData\\Local\\Temp\\ipykernel_11452\\2260934871.py:24: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "pdfs_file = [\"diretivas/questoes_prinpicais - all_tables_combined.pdf\",\n",
    "             \"diretivas/questoes_alternativas - questoes_alternativas.pdf\",\n",
    "             \"diretivas/Exemplo de plano de aula.pdf\"]\n",
    "for i in range(len(pdfs_file)):\n",
    "    vectorstore = embed_pdf_file(pdfs_file[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7337eb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "You are an assistant for question-answering tasks.\n",
      "Use the following pieces of retrieved context to answer\n",
      "the question. If you don't know the answer, say that you\n",
      "don't know. DON'T MAKE UP ANYTHING.\n",
      "\n",
      "Tabela 5: Alternativas a serem exploradas se um desafio de comunicação for identificado.\n",
      "Questão Alternativas\n",
      "Quais sensores são necessários para aprender o código de comunicação? \n",
      "O participante consegue usar esses sensores?- É possível tornar esse código disponível por meio de outros sensores?\n",
      "- Existe algum conversor automático que traduz o material de aprendizado \n",
      "para outros sensores?\n",
      "- Há pessoas disponíveis para fazer essa conversão?\n",
      "- As ferramentas e o método usados para ensinar o código são apropriados?\n",
      "Quantas regras de comunicação devem ser armazenadas? O participante\n",
      "consegue armazenar essa quantidade de informações?- São necessárias todas as regras para a tarefa específica?\n",
      "- O código pode ser simplificado?\n",
      "- É possível treinar outros participantes para cooperar sem algumas regras \n",
      "de comunicação?\n",
      "- Há suporte computacional disponível para complementar isso?\n",
      "O participante consegue memorizar o código durante toda a tarefa?- É possível fazer interrupções durante a tarefa para lembrar partes do código?\n",
      "- Existe algum suporte computacional para complementar isso?\n",
      "O participante consegue codificar as mensagens corretamente?- O código pode ser simplificado?\n",
      "- Existe suporte computacional para complementar isso?\n",
      "O participante consegue enviar mensagens usando os músculos?- Existem outros códigos que podem ser usados (por exemplo, gestos em \n",
      "substituição às palavras)? Se sim, esses códigos são suficientes para transmitir a mensagem?\n",
      "\n",
      "---\n",
      "\n",
      "Tabela 6: Alternativas que podem ser exploradas se um desafio de coordenação for identificado.\n",
      "Questão Alternativas\n",
      "Quais sensores são necessários para aprender as regras de coordenação? \n",
      "O participante é capaz de usar esses sensores?- É possível disponibilizar este código através de outros sensores?\n",
      "- Existe algum conversor automático que traduza o material de aprendizagem para outros \n",
      "sensores?\n",
      "- Há pessoas disponíveis para fazer essa conversão?\n",
      "- As ferramentas e métodos usados para ensinar as regras são apropriados?\n",
      "Quantas regras de coordenação devem ser armazenadas? O participante é capaz \n",
      "de armazenar essa quantidade de informação?- Todas as regras são necessárias para a tarefa específica?\n",
      "- Elas podem ser simplificadas?\n",
      "- É possível treinar outros participantes para cooperar sem algumas regras de comunicação?\n",
      "- Há suporte computacional para complementar isso?\n",
      "O participante é capaz de memorizar as regras de coordenação durante a tarefa?- É possível fazer interrupções durante a tarefa para lembrar partes das regras?\n",
      "- Pode o software de grupo coordenar a participação?\n",
      "- Há suporte computacional para complementar isso?\n",
      "O participante é capaz de respeitar o momento adequado para agir e se comunicar?\n",
      "- Pode o groupware informar quando o participante está autorizado a agir e se comunicar?\n",
      "- Pode alguém informar quando o participante está autorizado a agir e se comunicar?\n",
      "\n",
      "---\n",
      "\n",
      "- Existe algum suporte computacional para complementar isso?\n",
      "O participante consegue codificar as mensagens corretamente?- O código pode ser simplificado?\n",
      "- Existe suporte computacional para complementar isso?\n",
      "O participante consegue enviar mensagens usando os músculos?- Existem outros códigos que podem ser usados (por exemplo, gestos em \n",
      "substituição às palavras)? Se sim, esses códigos são suficientes para transmitir a mensagem?\n",
      "O participante consegue decodificar as mensagens corretamente?- É possível usar um tradutor automático do código atual para um mais palatável?\n",
      "- Há pessoas disponíveis para decodificar a mensagem e transmiti-la ao participante?\n",
      "O participante consegue receber mensagens usando sensores?- Existe algum conversor automático que traduz mensagens para outros sensores\n",
      " (por exemplo, visão computacional para identificar gestos e sintetizá-los; conversores de\n",
      " áudio para linguagem de sinais)?\n",
      "- Há pessoas disponíveis para fazer essa conversão?\n",
      "- Outros participantes podem enviar essas mensagens para outros sensores \n",
      "(por exemplo, comunicando verbalmente o que está sendo apontado)?\n",
      "O tempo necessário para processar as mensagens é adequado \n",
      "à dinâmica da tarefa?\n",
      "- É possível modificar a dinâmica da tarefa? Caso contrário, a inclusão nessa tarefa \n",
      "pode não ser possível?O tempo necessário para produzir mensagens é adequado \n",
      "à dinâmica da tarefa?\n",
      "O processo de comunicação é sem esforço?- O participante está ciente disso?\n",
      "\n",
      "---\n",
      "\n",
      "Tabela 8: Alternativas que podem ser exploradas se um desafio de consciência for identificado.\n",
      "Questão Alternativas\n",
      "Quais sensores são necessários para estar ciente das mudanças nos artefatos? \n",
      "O participante é capaz de usar esses sensores?\n",
      "- É possível disponibilizar esta informação através de outros sensores?\n",
      "- Existe algum conversor automático que traduza o material de aprendizagem para outros sensores?\n",
      "- Há pessoas disponíveis para fazer essa conversão?Quais sensores são necessários para estar ciente do que os outros estão fazendo? \n",
      "O participante é capaz de usar esses sensores?\n",
      "Quais sensores são necessários para estar ciente do feedback dos recursos? \n",
      "O participante é capaz de usar esses sensores?\n",
      "O participante é capaz de memorizar o que os outros estão fazendo?- O groupware pode fornecer esta informação aos participantes?\n",
      "- Esta informação pode ser atualizada antes de iniciar a tarefa?\n",
      "- Pode alguém ajudar o participante fornecendo esta informação? O participante é capaz de memorizar as mudanças nos artefatos?\n",
      "O participante é capaz de relacionar informações de conscientização com outros \n",
      "componentes da colaboração?- Pode alguém oferecer suporte quanto a isso?\n",
      "- O groupware pode oferecer suporte quanto a isso?\n",
      "Quais informações de conscientização o participante deve armazenar para realizar a \n",
      "tarefa? O participante é capaz de memorizar essas informações?- Pode o software de grupo fornecer esta informação aos participantes?\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: Levando em consideracao as tabelas 1 a 8,\n",
      "                   quais as questoes de acessibilidae que um jovem com autismo pode encontrar e quais possiveis solucoes?\n",
      "\n",
      "As questões de acessibilidade que um jovem com autismo pode encontrar incluem:\n",
      "\n",
      "1. Dificuldade em se comunicar com outras pessoas\n",
      "2. Dificuldade em entender as regras de comunicação e coordenação\n",
      "3. Dificuldade em memorizar informações\n",
      "4. Dificuldade em codificar e decodificar mensagens\n",
      "5. Dificuldade em usar sensores para se comunicar e receber informações\n",
      "6. Dificuldade em se conectar com outras pessoas\n",
      "7. Dificuldade em se adaptar a mudanças nos artefatos\n",
      "8. Dificuldade em se conectar com o feedback dos recursos\n",
      "\n",
      "Possíveis soluções para essas questões de acessibilidade incluem:\n",
      "\n",
      "1. Usando ferramentas de comunicação como sinais, gestos e ferramentas de comunicação assistida\n",
      "2. Usando ferramentas de coordenação como tabelas, gráficos e mapas\n",
      "3. Usando ferramentas de memória como listas, anotações e lembretes\n",
      "4. Usando ferramentas de codificação e decodificação como códigos de cor, símbolos e códigos de palavras\n",
      "5. Usando ferramentas de sensores como sensores de visão, audição e toque\n",
      "6. Usando ferramentas de conexão como ferramentas de comunicação assistida, ferramentas de coordenação e ferramentas de memória\n",
      "7. Usando ferramentas de adaptação como ferramentas de comunicação assistida, ferramentas de coordenação e ferramentas de memória\n",
      "8. Usando ferramentas de feedback como ferramentas de comunicação assistida, ferramentas de coordenação e ferramentas de memória.\n",
      "\n",
      "Em resumo, as tabelas 1 a 8 fornecem informações sobre possíveis desafios de acessibilidade que um jovem com autismo pode encontrar e possíveis soluções para esses desafios. Essas informações podem ajudar os profissionais a desenvolver estratégias para ajudar os jovens com autismo a se comunicar e colaborar com outras pessoas.\n"
     ]
    }
   ],
   "source": [
    "answer = generate(\"\"\"Levando em consideracao as tabelas 1 a 8,\n",
    "                   quais as questoes de acessibilidae que um jovem com autismo pode encontrar e quais possiveis solucoes?\"\"\",\n",
    "                   vectorstore)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
